# -*- coding: utf-8 -*-
"""main-torch.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Xc221p6DLBlfVsklbWzisGY1pMs3tz5j
"""

! pip install -q kaggle
from google.colab import files
files.upload()

import opendatasets as od
  
od.download(
    "https://www.kaggle.com/datasets/muratkokludataset/rice-image-dataset")

import numpy as np
import os
import cv2
from sklearn.model_selection import train_test_split
from tqdm import tqdm
import matplotlib.pyplot as plt
import torch
import random
import pathlib
from torch import nn
from torch.utils.data import Dataset
from random import randint
from tqdm import tqdm
from PIL import Image
import matplotlib.image as img
from torch.utils.data import DataLoader
import torch.nn.functional as tnf
import torchvision.transforms as transforms

"""## Import Data"""

data_path = '/content/rice-image-dataset/Rice_Image_Dataset/'
data_dir = pathlib.Path(data_path)

arborio = list(data_dir.glob('Arborio/*'))[:1]
basmati = list(data_dir.glob('Basmati/*'))[:1]
ipsala = list(data_dir.glob('Ipsala/*'))[:1]
jasmine = list(data_dir.glob('Jasmine/*'))[:1]
karacadag = list(data_dir.glob('Karacadag/*'))[:1]


data_labels = {
    'Arborio' : 0,
    'Basmati' : 1,
    'Ipsala' : 2,
    'Jasmine' : 3,
    'Karacadag': 4
}

class_names = ['Arborio', 'Basmati', 'Ipsala', 'Jasmine','Karacadag']
n_classes = len(class_names)
images = [[os.path.join(data_path, class_name, x) 
                for x in os.listdir(os.path.join(data_path, class_name))]
                for class_name in class_names]

images_path = []
for i in range(5):
    for j in range(len(images[i])):
        now = images[i]
        images_path.append(now[j])


random.shuffle(images_path)
train_data = images_path[:50000]
validation_data = images_path[50000:60000]
test_data = images_path[60000:]

fig, ax = plt.subplots(ncols=5, figsize=(20,5))
fig.suptitle('Rice Category')
arborio_image = img.imread(arborio[0])
basmati_image = img.imread(basmati[0])
ipsala_image = img.imread(ipsala[0])
jasmine_image = img.imread(jasmine[0])
karacadag_image = img.imread(karacadag[0])

ax[0].set_title('arborio')
ax[1].set_title('basmati')
ax[2].set_title('ipsala')
ax[3].set_title('jasmine')
ax[4].set_title('karacadag')


ax[0].imshow(arborio_image)
ax[1].imshow(basmati_image)
ax[2].imshow(ipsala_image)
ax[3].imshow(jasmine_image)
ax[4].imshow(karacadag_image)

len(images_path)

"""## initializing the Dataset class:"""

trans = transforms.Compose([
    transforms.Resize((28,28)),
    transforms.ToTensor(),
    transforms.Normalize((0.5), (0.5))
])

class IMGdataset(Dataset):
    def __init__(self, data_labels, direction, transforms=None):
        super().__init__()

        self.data_labels = data_labels
        self.direction = direction
        self.transforms = transforms

    def __len__(self):
        return len(self.direction)

    def __getitem__(self, index):
        img_path = self.direction[index]
        img = Image.open(img_path)
        l = img_path.split('/')[-1]
        lab_name = l.split(' ')[-2]
        label = self.data_labels[lab_name.capitalize()]

        if self.transforms is not None:
            img = self.transforms(img)
        return (img, label)

train = IMGdataset(data_labels, train_data, trans)
validation = IMGdataset(data_labels, validation_data, trans)
test = IMGdataset(data_labels, test_data, trans)

train_ds = DataLoader(train, batch_size = 64, shuffle = True)
val_ds = DataLoader(validation, batch_size = 64, shuffle = True)
test_ds = DataLoader(test, batch_size = 64, shuffle = True)

"""## Build the Model:"""

class Model(nn.Module):
    def __init__(self):
        super().__init__()

        self.l1 = nn.Conv2d(in_channels=3, out_channels=4, kernel_size=3)
        self.l2 = nn.Conv2d(in_channels=4, out_channels=16, kernel_size=3)
        self.l3 = nn.MaxPool2d(kernel_size=(2,2))
        self.l4 = nn.Linear(400, 128)
        self.l5 = nn.Linear(128, 5)

    def forward(self, x):
        x = self.l1(x)
        x = self.l3(x)
        x = tnf.relu(x)
        x = self.l2(x)    
        x = self.l3(x)        
        x = tnf.relu(x)
        x = torch.flatten(x , 1)
        x = self.l4(x)
        x = tnf.relu(x)
        x = self.l5(x)

        return x

model = Model()

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = model.to(device)
from torch.optim import Adam
op = Adam(model.parameters(), lr = 0.001)
lossf = tnf.cross_entropy

"""# train class:"""

def training(model, epoch, train_ds):
    model.train()
    total_num = len(train_ds.dataset)
    train_loss = 0
    correct_num = 0

    for image, label in tqdm(train_ds):
        image = image.to(device)
        label = label.to(device)
        label = label.to(torch.long)

        output = model(image)
        loss = lossf(output, label)
        train_loss += loss.item() * label.size(0)
        op.zero_grad()
        loss.backward()
        op.step()

        predict = torch.argmax(output, dim=-1)
        correct_num += label.eq(predict).sum()

    train_loss = train_loss / total_num
    train_acc = correct_num / total_num
    print('epoch: {} --> train_loss: {:.6f} - train_acc: {:.6f} - '.format(
        epoch, train_loss, train_acc), end='')

for epoch in range(10):
    training(model, epoch, train_ds)

def evaluate(model, eval_ds, mode='val'):
    model.eval()

    total_num = len(eval_ds.dataset)
    eval_loss = 0
    correct_num = 0

    for image, label in tqdm(eval_ds):
        image = image.to(device)
        label = label.to(device)
        label = label.to(torch.long)
        
        output = model(image)
        loss = lossf(output, label)
        eval_loss += loss.item() * label.size(0)

        predict = torch.argmax(output, dim=-1)
        correct_num += label.eq(predict).sum()
    
    eval_loss = eval_loss / total_num
    eval_acc = correct_num / total_num
    
    print('{}_loss: {:.6f} - {}_acc: {:.6f}'.format(
        mode, eval_loss, mode, eval_acc))

evaluate(model, test_ds, mode='test')